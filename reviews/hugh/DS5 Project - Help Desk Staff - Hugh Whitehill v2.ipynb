{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS5 Project - Help Desk Staff - Hugh Whitehill v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "OVERVIEW\n",
    "\n",
    "> I work for an IT outsourcing company that targets the financial services industry. We have a Help Desk that receives a lot of traffic (mainly via phone calls) and deals with a lot of support issues and IT related requests from a large client base. Ths focus of this project will be on our London, UK Help Desk. \n",
    "\n",
    "\n",
    "THE PROBLEM\n",
    "\n",
    "> Currently we see low utilization for the Help Desk staff but at differnet times. Our main services fall into 2 categories: Planned work (pre-booked tasks, projects etc.) and Ad-Hoc Requests (support when required, normally via the Help Desk). \n",
    "\n",
    "> Staff levels on the Help Desk are hard to gauge and can lead to under staffing or over staffing. \n",
    "\n",
    "> If we can know in advance (predict) what staffing levels we need then we can either allocate the staff to Planned work (pre-booked tasks) and therefore get better utlisation or arrange for additional staff to cope with high demand thus providing a better service to our clients.  \n",
    "\n",
    "> As a company, staff is our highest cost so utilizing them as much as possible can increase margins and make us more effecient whilst minimising the need to simply add more staff as the business grows. \n",
    "\n",
    "\n",
    "THE APPROACH\n",
    "\n",
    "> My theory is that factors outside of the company and our control such as weather, public transport, finance markets etc. influence the volume of calls and workload on the Help Desk. By looking at internal company data and comparing with outside data the idea is to predict in advance the required staffing levels. The earlier we can know how to staff the better. I think this can add a lot of value to the business.\n",
    "\n",
    "\n",
    "THE DATA\n",
    "\n",
    "> The data that was easiest to obtain was the full year of 2014. I have access to more data but for the timing of this project and privacy reasons this is what I will start with. The end goal would be to have the data exported automatically from souces such as API's, SFTP transfers then algorithm applied against it and then results updated on a web based dashboard for the business to access. \n",
    "\n",
    "* NYSE COMPOSITE - 2014 - CSV - http://finance.yahoo.com/q/hp?s=%5ENYA+Historical+Prices\n",
    "\n",
    "* FTSE 100       - 2014 - CSV - http://finance.yahoo.com/q/hp?s=%5EFTSE+Historical+Prices\n",
    "\n",
    "* London Weather - 2014 - CSV - https://weatherspark.com/\n",
    "\n",
    "* HelpDesk Calls - 2014 - CSV - Internal Company Data. Exported Phone logs. [Data altered by random %]\n",
    "\n",
    "* Tickets        - 2014 - CSV - Internal Company Data. Exported from ticket system. [Data altered by random %]\n",
    "\n",
    "* Still trying to get good London Underground(Tube) data on their outages for 2014 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELLING TECHNIQUE\n",
    "\n",
    "> This is about as far as I got. If you see the image below, what I am trying to do is look for a pattern (does stock price affect call volume, does weather effect call volume etc.) by doing EDA and eyeballing. Then with the data I have apply an algorithm to prove the relationship. After the project I will then go back and see how much historical company data I can find and use this to refine. Plus any future data once I setup the pipeline. \n",
    "\n",
    "Based on the examples we have used in class I think I need to use some sort of regression. Considering I have had no time to do my homework I am not sure next step as I didnt see the previous examples all the way through. Help! ;-) \n",
    "\n",
    "https://drive.google.com/open?id=0B04ufcHgYOr_ampyV0NFajQ3RzhieUZVcGVuNWxRdmRIRE1F&authuser=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps and Plan, Act, Check, Do to keep improving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

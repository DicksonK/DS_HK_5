{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "window.load_remote_theme = false\n",
       "var theme_url = \"https://drostehk.github.io/ipynb-theme/\";\n",
       "var asset_url = 'https://raw.githubusercontent.com/tijptjik/DS_assets/master/';\n",
       "\n",
       "window.load_local_theme = function(){\n",
       "    var hostname = document.location.hostname\n",
       "    return ((hostname == \"localhost\" || hostname == '127.0.0.1') && !load_remote_theme)\n",
       "}\n",
       "\n",
       "var url = load_local_theme() ? document.location.origin + \"/files/theme/custom.js\" : theme_url + 'custom.js'\n",
       "\n",
       "$.getScript(url)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "window.load_remote_theme = false\n",
    "var theme_url = \"https://drostehk.github.io/ipynb-theme/\";\n",
    "var asset_url = 'https://raw.githubusercontent.com/tijptjik/DS_assets/master/';\n",
    "\n",
    "window.load_local_theme = function(){\n",
    "    var hostname = document.location.hostname\n",
    "    return ((hostname == \"localhost\" || hostname == '127.0.0.1') && !load_remote_theme)\n",
    "}\n",
    "\n",
    "var url = load_local_theme() ? document.location.origin + \"/files/theme/custom.js\" : theme_url + 'custom.js'\n",
    "\n",
    "$.getScript(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, division\n",
    "\n",
    "import IPython\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import *\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display as prnt\n",
    "\n",
    "# Matplotlib in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Notebook Options\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Matplotlib Styles\n",
    "c = {'axes.labelsize': 17,\n",
    "'axes.titlesize': 16,\n",
    "'figure.figsize': [18, 8],\n",
    "'grid.linewidth': 1.6,\n",
    "'legend.fontsize': 17,\n",
    "'lines.linewidth': 2,\n",
    "'lines.markeredgewidth': 0.0,\n",
    "'lines.markersize': 11,\n",
    "'patch.linewidth': 0.5,\n",
    "'xtick.labelsize': 16,\n",
    "'xtick.major.pad': 20,\n",
    "'xtick.major.width': 2,\n",
    "'xtick.minor.width': 1,\n",
    "'ytick.labelsize': 16.0,\n",
    "'ytick.major.pad': 20,\n",
    "'ytick.major.width': 2,\n",
    "'ytick.minor.width': 1 }\n",
    "wide_c = dict(c, **{'figure.figsize':[20,8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def table(df,replace_match=\"\",replace_str=\"\"):\n",
    "    return IPython.display.display(HTML(df.to_html().replace('<table border=\"1\" class=\"dataframe\">','<table class=\"table table-striped table-hover\">').replace(replace_match,replace_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/bikeshare/'\n",
    "TRAIN_FILE = DATA_DIR + 'train.csv'\n",
    "TEST_FILE = DATA_DIR + 'test.csv'\n",
    "df = pd.read_csv(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    # Loads the training data, but splits the y from the X\n",
    "    dfx = pd.read_csv(TRAIN_FILE)\n",
    "    return dfx.iloc[:, 0:9], dfx.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# First, we should set up some sort of testing framework, so that we can benchmark our progress as we go\n",
    "# The evaluation metric is Root mean squared logarithmic error.\n",
    "def rmsele(actual, pred):\n",
    "    \"\"\"\n",
    "    Given a column of predictions and a column of actuals, calculate the RMSELE\n",
    "    \"\"\"\n",
    "    squared_errors = (np.log(pred + 1) - np.log(actual + 1)) ** 2\n",
    "    mean_squared = np.sum(squared_errors) / len(squared_errors)\n",
    "    return np.sqrt(mean_squared)\n",
    "\n",
    "# This helper function will make a callable that we can use in cross_val_score\n",
    "rmsele_scorer = make_scorer(rmsele, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5691983019475926"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "expected_value = df['count'].mean()\n",
    "yhat = np.array([expected_value] * len(df['count']))\n",
    "\n",
    "rmsele(df['count'].values, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "# Lets just train a basic model so that we can test if our scoring and\n",
    "# cross validation framework works well. We'll use a Ridge regression,\n",
    "# which is a form of linear regression\n",
    "X, y = get_train_data()\n",
    "# Subset the X to just use temp, atemp, and workingday\n",
    "Xhat = X[['temp', 'atemp', 'humidity']]\n",
    "ridge_estimator = Ridge(normalize=True)\n",
    "scores = cross_val_score(ridge_estimator, Xhat, y, scoring=rmsele_scorer, cv=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24286060181991254"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_train_data()\n",
    "# Subset the X to just use temp, atemp, and workingday\n",
    "Xhat = X[['temp', 'atemp', 'humidity']]\n",
    "ridge_estimator = Ridge()\n",
    "ridge_estimator.fit(Xhat,y).score(Xhat,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in some of the parameters on cross_val_score\n",
    "def perform_cv(estimator, X, y):\n",
    "    return cross_val_score(estimator, X, y, scoring=rmsele_scorer, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2011-01-08 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2011-01-08 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2011-01-11 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2011-01-11 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2011-01-11 18:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2011-01-11 19:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>11.365</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2011-01-11 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.575</td>\n",
       "      <td>93</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2011-01-11 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2011-01-11 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2011-01-12 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2011-01-12 05:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2011-01-12 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.92</td>\n",
       "      <td>7.575</td>\n",
       "      <td>93</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2011-01-17 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.060</td>\n",
       "      <td>93</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2011-01-17 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.820</td>\n",
       "      <td>86</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2011-02-01 05:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>10.605</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>2011-02-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>10.605</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2011-02-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>11.365</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2011-02-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.56</td>\n",
       "      <td>11.365</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2011-02-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.56</td>\n",
       "      <td>11.365</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2011-02-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.56</td>\n",
       "      <td>11.365</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2011-02-01 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2011-02-02 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2011-02-05 05:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2011-02-05 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>12.880</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2011-02-05 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2011-02-05 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2011-02-05 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.605</td>\n",
       "      <td>100</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2011-02-05 11:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2011-02-05 12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2011-02-05 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2011-02-05 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2011-02-05 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2011-02-05 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2011-02-05 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>100</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2011-02-05 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>100</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2011-02-07 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.56</td>\n",
       "      <td>11.365</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2011-02-09 19:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.060</td>\n",
       "      <td>86</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2011-02-09 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2011-02-09 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2011-02-10 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.820</td>\n",
       "      <td>86</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2011-02-12 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6.820</td>\n",
       "      <td>93</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2011-02-12 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>2011-03-06 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.48</td>\n",
       "      <td>12.120</td>\n",
       "      <td>100</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2011-03-06 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.090</td>\n",
       "      <td>93</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2011-03-06 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.02</td>\n",
       "      <td>9.850</td>\n",
       "      <td>100</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2011-03-06 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.02</td>\n",
       "      <td>9.850</td>\n",
       "      <td>100</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2011-03-07 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.090</td>\n",
       "      <td>100</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2011-03-07 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.090</td>\n",
       "      <td>100</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>2011-04-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>2011-04-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>2011-12-07 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>30.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>2011-12-12 07:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>86</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>2011-12-19 05:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>8.335</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5642</th>\n",
       "      <td>2012-01-10 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.090</td>\n",
       "      <td>93</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>2012-01-10 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>2012-01-10 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>2012-01-10 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>2012-01-10 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.850</td>\n",
       "      <td>93</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>2012-02-12 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.275</td>\n",
       "      <td>79</td>\n",
       "      <td>31.0009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  season  holiday  workingday  weather   temp  \\\n",
       "169   2011-01-08 08:00:00       1        0           0        3   6.56   \n",
       "170   2011-01-08 09:00:00       1        0           0        3   6.56   \n",
       "247   2011-01-11 16:00:00       1        0           1        2   6.56   \n",
       "248   2011-01-11 17:00:00       1        0           1        2   6.56   \n",
       "249   2011-01-11 18:00:00       1        0           1        3   6.56   \n",
       "250   2011-01-11 19:00:00       1        0           1        3   6.56   \n",
       "251   2011-01-11 20:00:00       1        0           1        3   6.56   \n",
       "253   2011-01-11 22:00:00       1        0           1        3   6.56   \n",
       "254   2011-01-11 23:00:00       1        0           1        3   6.56   \n",
       "257   2011-01-12 02:00:00       1        0           1        1   5.74   \n",
       "258   2011-01-12 05:00:00       1        0           1        1   5.74   \n",
       "259   2011-01-12 06:00:00       1        0           1        1   4.92   \n",
       "394   2011-01-17 22:00:00       1        1           0        3   5.74   \n",
       "395   2011-01-17 23:00:00       1        1           0        3   6.56   \n",
       "435   2011-02-01 05:00:00       1        0           1        3   5.74   \n",
       "436   2011-02-01 06:00:00       1        0           1        3   5.74   \n",
       "437   2011-02-01 07:00:00       1        0           1        3   6.56   \n",
       "438   2011-02-01 08:00:00       1        0           1        3   6.56   \n",
       "439   2011-02-01 09:00:00       1        0           1        2   6.56   \n",
       "440   2011-02-01 10:00:00       1        0           1        2   6.56   \n",
       "453   2011-02-01 23:00:00       1        0           1        3   8.20   \n",
       "464   2011-02-02 10:00:00       1        0           1        2   9.02   \n",
       "529   2011-02-05 05:00:00       1        0           0        3   8.20   \n",
       "530   2011-02-05 06:00:00       1        0           0        3   8.20   \n",
       "532   2011-02-05 08:00:00       1        0           0        3   8.20   \n",
       "533   2011-02-05 09:00:00       1        0           0        3   8.20   \n",
       "534   2011-02-05 10:00:00       1        0           0        3   8.20   \n",
       "535   2011-02-05 11:00:00       1        0           0        3   9.02   \n",
       "536   2011-02-05 12:00:00       1        0           0        3   9.02   \n",
       "537   2011-02-05 13:00:00       1        0           0        3   9.02   \n",
       "538   2011-02-05 14:00:00       1        0           0        3   9.02   \n",
       "539   2011-02-05 15:00:00       1        0           0        3   9.02   \n",
       "540   2011-02-05 16:00:00       1        0           0        3   9.02   \n",
       "541   2011-02-05 17:00:00       1        0           0        2   9.84   \n",
       "545   2011-02-05 21:00:00       1        0           0        1  10.66   \n",
       "580   2011-02-07 08:00:00       1        0           1        2   6.56   \n",
       "638   2011-02-09 19:00:00       1        0           1        3   5.74   \n",
       "639   2011-02-09 20:00:00       1        0           1        3   5.74   \n",
       "640   2011-02-09 21:00:00       1        0           1        2   5.74   \n",
       "643   2011-02-10 00:00:00       1        0           1        3   5.74   \n",
       "694   2011-02-12 06:00:00       1        0           0        1   4.92   \n",
       "696   2011-02-12 08:00:00       1        0           0        1   5.74   \n",
       "1016  2011-03-06 20:00:00       1        0           0        3  11.48   \n",
       "1017  2011-03-06 21:00:00       1        0           0        3   9.84   \n",
       "1018  2011-03-06 22:00:00       1        0           0        2   9.02   \n",
       "1019  2011-03-06 23:00:00       1        0           0        2   9.02   \n",
       "1020  2011-03-07 00:00:00       1        0           1        3   8.20   \n",
       "1021  2011-03-07 01:00:00       1        0           1        3   8.20   \n",
       "1323  2011-04-01 00:00:00       2        0           1        3  10.66   \n",
       "1324  2011-04-01 01:00:00       2        0           1        3  10.66   \n",
       "5132  2011-12-07 22:00:00       4        0           1        3   9.84   \n",
       "5237  2011-12-12 07:00:00       4        0           1        1   5.74   \n",
       "5403  2011-12-19 05:00:00       4        0           1        1   5.74   \n",
       "5642  2012-01-10 06:00:00       1        0           1        2   7.38   \n",
       "5643  2012-01-10 07:00:00       1        0           1        2   7.38   \n",
       "5644  2012-01-10 08:00:00       1        0           1        2   7.38   \n",
       "5645  2012-01-10 09:00:00       1        0           1        2   7.38   \n",
       "5646  2012-01-10 10:00:00       1        0           1        2   7.38   \n",
       "6139  2012-02-12 01:00:00       1        0           0        3   3.28   \n",
       "\n",
       "       atemp  humidity  windspeed  \n",
       "169    9.090        93     7.0015  \n",
       "170    9.090        93     7.0015  \n",
       "247    7.575        86    15.0013  \n",
       "248    7.575        86    15.0013  \n",
       "249    9.090        93     7.0015  \n",
       "250   11.365        93     0.0000  \n",
       "251    7.575        93    12.9980  \n",
       "253    9.090        93     7.0015  \n",
       "254    9.850        93     6.0032  \n",
       "257    7.575        86     8.9981  \n",
       "258    7.575        86    11.0014  \n",
       "259    7.575        93     8.9981  \n",
       "394    6.060        93    16.9979  \n",
       "395    6.820        86    19.0012  \n",
       "435   10.605        93     0.0000  \n",
       "436   10.605        93     0.0000  \n",
       "437   11.365        93     0.0000  \n",
       "438   11.365        93     0.0000  \n",
       "439   11.365        93     0.0000  \n",
       "440   11.365        93     0.0000  \n",
       "453    9.850        93    12.9980  \n",
       "464   13.635       100     0.0000  \n",
       "529   11.365       100     6.0032  \n",
       "530   12.880       100     0.0000  \n",
       "532   11.365       100     6.0032  \n",
       "533   11.365       100     6.0032  \n",
       "534   10.605       100     8.9981  \n",
       "535   11.365       100     8.9981  \n",
       "536   11.365       100    11.0014  \n",
       "537   11.365       100    11.0014  \n",
       "538   13.635       100     0.0000  \n",
       "539   13.635       100     0.0000  \n",
       "540   11.365       100     8.9981  \n",
       "541   10.605       100    19.0012  \n",
       "545   12.880       100    12.9980  \n",
       "580   11.365       100     0.0000  \n",
       "638    6.060        86    16.9979  \n",
       "639    7.575        86    11.0014  \n",
       "640    7.575        86    11.0014  \n",
       "643    6.820        86    12.9980  \n",
       "694    6.820        93    12.9980  \n",
       "696    7.575        86     8.9981  \n",
       "1016  12.120       100    27.9993  \n",
       "1017   9.090        93    40.9973  \n",
       "1018   9.850       100    26.0027  \n",
       "1019   9.850       100    27.9993  \n",
       "1020   9.090       100    22.0028  \n",
       "1021   9.090       100    22.0028  \n",
       "1323  12.880       100    11.0014  \n",
       "1324  12.880       100    11.0014  \n",
       "5132   9.850        93    30.0026  \n",
       "5237   7.575        86     8.9981  \n",
       "5403   8.335        93     7.0015  \n",
       "5642   9.090        93    12.9980  \n",
       "5643   9.850        93    11.0014  \n",
       "5644   9.850        93    11.0014  \n",
       "5645   9.850        93    11.0014  \n",
       "5646   9.850        93    11.0014  \n",
       "6139   2.275        79    31.0009  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[ridge_estimator.predict(Xhat) < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -1.40707, std: 0.13649, params: {u'alpha': 1.0},\n",
       " mean: -1.40707, std: 0.13649, params: {u'alpha': 1.6681005372000588},\n",
       " mean: -1.40707, std: 0.13649, params: {u'alpha': 2.7825594022071245},\n",
       " mean: -1.40707, std: 0.13649, params: {u'alpha': 4.6415888336127784},\n",
       " mean: -1.40707, std: 0.13649, params: {u'alpha': 7.7426368268112693},\n",
       " mean: -1.40706, std: 0.13649, params: {u'alpha': 12.915496650148841},\n",
       " mean: -1.40705, std: 0.13650, params: {u'alpha': 21.544346900318832},\n",
       " mean: -1.40703, std: 0.13650, params: {u'alpha': 35.938136638046259},\n",
       " mean: -1.40701, std: 0.13651, params: {u'alpha': 59.948425031894089},\n",
       " mean: -1.40697, std: 0.13652, params: {u'alpha': 100.0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Try a simple grid search with the estimator\n",
    "parameters = {'alpha': np.logspace(0, 2, 10)}\n",
    "grid = GridSearchCV(ridge_estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
    "grid.fit(Xhat, y)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And for grid_search\n",
    "def perform_grid_search(estimator, parameters, X, y):\n",
    "    grid_search = GridSearchCV(estimator, parameters, scoring=rmsele_scorer, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhat = X[['temp', 'atemp', 'humidity']]\n",
    "normalize = StandardScaler()\n",
    "normalize.fit(Xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.79123196   8.47421137  19.24414932]\n",
      "[ 20.23085982  23.65508405  61.88645967]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.333661</td>\n",
       "      <td>-1.092737</td>\n",
       "      <td>0.993213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.438907</td>\n",
       "      <td>-1.182421</td>\n",
       "      <td>0.941249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.438907</td>\n",
       "      <td>-1.182421</td>\n",
       "      <td>0.941249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.333661</td>\n",
       "      <td>-1.092737</td>\n",
       "      <td>0.681430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.333661</td>\n",
       "      <td>-1.092737</td>\n",
       "      <td>0.681430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp     atemp  humidity\n",
       "0 -1.333661 -1.092737  0.993213\n",
       "1 -1.438907 -1.182421  0.941249\n",
       "2 -1.438907 -1.182421  0.941249\n",
       "3 -1.333661 -1.092737  0.681430\n",
       "4 -1.333661 -1.092737  0.681430"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print normalize.std_\n",
    "print normalize.mean_\n",
    "(Xhat - Xhat.mean()) / Xhat.std()\n",
    "((Xhat - normalize.mean_) / normalize.std_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.63396695, -1.47964703, -1.34164532, -1.33777304, -1.241764  ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Now lets move on to the actual transformation of the inputs\n",
    "# First, not every estimator we'll use will have the \"normalize\" keyword\n",
    "# So let's break it out into a transformer, so that we have better control over it\n",
    "ridge_estimator = Ridge()\n",
    "\n",
    "normalize = StandardScaler()\n",
    "Xhat = X[['temp', 'atemp', 'humidity']]\n",
    "Xhat = normalize.fit_transform(Xhat)\n",
    "\n",
    "scores = perform_cv(ridge_estimator, Xhat, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.63397871, -1.4796492 , -1.34164469, -1.33777294, -1.24175033])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# Now we have the beginnings of a multi-step pipeline\n",
    "# Scikit lets you wrap each of these steps into a Pipeline object,\n",
    "# so you just have to run fit / predict once\n",
    "# instead of manually feeding the data from one transformer to the next\n",
    "normalize = StandardScaler()\n",
    "ridge_estimator = Ridge()\n",
    "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
    "Xhat = X[['temp', 'atemp', 'humidity']]\n",
    "scores = perform_cv(pipeline, Xhat, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -1.40698, std: 0.13651, params: {u'ridge__alpha': 1.0},\n",
       " mean: -1.40688, std: 0.13653, params: {u'ridge__alpha': 2.1544346900318838},\n",
       " mean: -1.40671, std: 0.13658, params: {u'ridge__alpha': 4.6415888336127784},\n",
       " mean: -1.40642, std: 0.13668, params: {u'ridge__alpha': 10.0},\n",
       " mean: -1.40603, std: 0.13688, params: {u'ridge__alpha': 21.544346900318832},\n",
       " mean: -1.40652, std: 0.13871, params: {u'ridge__alpha': 46.415888336127772},\n",
       " mean: -1.41912, std: 0.13725, params: {u'ridge__alpha': 100.0},\n",
       " mean: -1.41035, std: 0.13756, params: {u'ridge__alpha': 215.44346900318823},\n",
       " mean: -1.40951, std: 0.13878, params: {u'ridge__alpha': 464.15888336127773},\n",
       " mean: -1.42265, std: 0.13961, params: {u'ridge__alpha': 1000.0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additionally, you can perform grid search over all of the steps of the pipeline\n",
    "# So you don't have to tune each step manually\n",
    "# The pipeline exposes the underlying steps' parameters like so:\n",
    "# ridge__alpha, and normalize__with_mean\n",
    "ridge_estimator = Ridge()\n",
    "\n",
    "normalize = StandardScaler()\n",
    "parameters = {'ridge__alpha': np.logspace(0, 3, 10)}\n",
    "Xhat = X[['temp', 'atemp', 'humidity']]\n",
    "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, scoring=rmsele_scorer, cv=5)\n",
    "grid.fit(Xhat, y)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer\n",
    "# Lets move on to including more features in our model\n",
    "# We probably want to use a factor like Season in our model, but it's\n",
    "# a categorical feature, and we'll need to convert it to a series of booleans\n",
    "one_hot = OneHotEncoder()\n",
    "season = one_hot.fit_transform(X['season'].reshape(X.shape[0], 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.fit_transform(X['season'].reshape(X.shape[0], 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.48713408, -1.44375715, -1.42074189, -1.27959987, -1.2144014 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then have to join this with the other variables\n",
    "normalize = StandardScaler()\n",
    "ridge_estimator = Ridge()\n",
    "pipeline = Pipeline([('normalize', normalize), ('ridge', ridge_estimator)])\n",
    "Xhat = np.hstack([X[['temp', 'atemp', 'humidity']], season])\n",
    "scores = perform_cv(pipeline, Xhat, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.49094937, -1.44178361, -1.41395979, -1.27575541, -1.21552556])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Actually there's a faster way of doing this with the argument 'categorical_features'\n",
    "class ToArray(BaseEstimator, TransformerMixin):\n",
    "    # We need this because OneHotEncoder returns a sparse array, and normalize requires a non-sparse array\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.toarray()\n",
    "        \n",
    "Xhat = X[['season', 'weather', 'temp', 'atemp', 'humidity']]\n",
    "# I think it needs to be 5 here, because it assumes that '0' is a possible value for an int datatype\n",
    "# Should probably specify the data types in read_csv\n",
    "one_hot = OneHotEncoder(n_values=[5, 5], categorical_features=[0, 1])\n",
    "desparse = ToArray()\n",
    "normalize = StandardScaler()\n",
    "ridge_estimator = Ridge()\n",
    "pipeline = Pipeline([('onehot', one_hot), ('desparse', desparse), ('normalize', normalize), ('ridge', ridge_estimator)])\n",
    "scores = perform_cv(pipeline, Xhat, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selective Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-84ba06bc1f46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mridge_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'normalize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'onehot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'desparse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'ridge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mridge_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-9d72c90b2b82>\u001b[0m in \u001b[0;36mperform_cv\u001b[1;34m(estimator, X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fill in some of the parameters on cross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mperform_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrmsele_scorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1361\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1459\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_pre_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-84ba06bc1f46>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSelectiveNormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/io/.tools/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[1;34m\"\"\" return the cached item, item represents a label indexer \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "# OK, so now we've got a pipeline that does one-hot encoding of two categorical variables\n",
    "# and then normalizes the variables\n",
    "# But actually we're not supposed to normalize the the dummy variables.\n",
    "# So we need some way of only normalizing non-dummy variables\n",
    "\n",
    "# Oops, actually the CV splitting converts the Pandas DF to an array, so we can't rely\n",
    "# on the normalize having the proper column names\n",
    "class SelectiveNormalize(StandardScaler):\n",
    "    def __init__(self, cols, copy=True, with_mean=True, with_std=True):\n",
    "        self.cols = cols\n",
    "        super(SelectiveNormalize, self).__init__(copy, with_mean, with_std)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        subset = X[:, self.cols]\n",
    "        return super(SelectiveNormalize, self).fit(subset, y)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        subset = X[:, self.cols]\n",
    "        normalized = super(SelectiveNormalize, self).transform(subset)\n",
    "        others = [col for col in range(X.shape[1]) if col not in self.cols]\n",
    "        res = np.hstack([normalized, X[:, others]])\n",
    "        return res\n",
    "\n",
    "Xhat = X[['season', 'weather', 'temp', 'atemp', 'humidity']]\n",
    "one_hot = OneHotEncoder(n_values=[5, 5], categorical_features=[3, 4])\n",
    "normalize = SelectiveNormalize([2, 3, 4])\n",
    "desparse = ToArray()\n",
    "ridge_estimator = Ridge()\n",
    "pipeline = Pipeline([('normalize', normalize), ('onehot', one_hot), ('desparse', desparse), ('ridge', ridge_estimator)])\n",
    "scores = perform_cv(pipeline, Xhat, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SelectiveNormalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d11522cf8d60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mget_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtractHour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectiveNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[0mdesparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mToArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mridge_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SelectiveNormalize' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Lets try tackling the date column now.  The time of day is probably really important\n",
    "# So we need some way of extracting the hour\n",
    "# We'll use a FeatureUnion to do this, to demonstrate the functionality\n",
    "def get_train_data():\n",
    "    # Loads the training data, but splits the y from the X\n",
    "    df = pd.read_csv(TRAIN_FILE, parse_dates=['datetime'])\n",
    "    return df.iloc[:, 0:9], df.iloc[:,-1]\n",
    "\n",
    "\n",
    "class SelectColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Passes on a subset of columns from an input ndarray\n",
    "    \"\"\"\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self.cols]\n",
    "    \n",
    "\n",
    "class ExtractHour(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extracts hour from a datetime series\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        res = np.zeros(X.shape)\n",
    "        for xx in xrange(X.shape[0]):\n",
    "            res[xx] = X[xx, 0].hour\n",
    "        return res.reshape(res.shape[0], 1)\n",
    "    \n",
    "\n",
    "class CastType(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cast_to):\n",
    "        self.cast_to = cast_to\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.astype(self.cast_to)\n",
    "\n",
    "X, y = get_train_data()\n",
    "# Reminder of the columns:\n",
    "# ['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed']\n",
    "select_date = SelectColumns([0])\n",
    "select_others = SelectColumns(range(1, 9))\n",
    "cast_float = CastType(np.float64)\n",
    "one_hot = OneHotEncoder(n_values=[5, 5], categorical_features=[0, 3])\n",
    "get_hour = ExtractHour()\n",
    "normalize = SelectiveNormalize(range(2, 8))\n",
    "desparse = ToArray()\n",
    "ridge_estimator = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "hour_feature = Pipeline([('select_date', select_date), ('get_hour', get_hour)])\n",
    "other_features = Pipeline([('select_others', select_others), ('cast_float', cast_float), ('onehot', one_hot), ('desparse', desparse)])\n",
    "join_features = FeatureUnion([('hour', hour_feature), ('others', other_features)])\n",
    "predict = Pipeline([('featurize', join_features), ('estimator', ridge_estimator)])\n",
    "scores = perform_cv(predict, X, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(df_test, prediction, filename='submission.csv'):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('datetime,count\\n')\n",
    "        submission_strings = df_test.reset_index()['datetime'] + ',' + prediction.astype(str)\n",
    "        for row in submission_strings:\n",
    "            f.write(row + '\\n')\n",
    "\n",
    "# make_submission(df_test, prediction, 'submission1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
